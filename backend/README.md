# AI Slop Detector Backend

A Cloudflare Workers-based backend API for the AI Content Detector Chrome Extension. This service analyzes web content to determine whether it was generated by AI or written by humans.

## Features

- **Content Analysis**: AI-powered analysis using OpenAI GPT-4 and Anthropic Claude
- **Intelligent Caching**: Multi-factor cache key strategy with content change detection
- **Rate Limiting**: Daily limits and abuse prevention
- **Authentication**: Google OAuth integration with JWT tokens
- **Global Edge Network**: Sub-100ms response times worldwide
- **TypeScript**: Full type safety and modern development experience

## Architecture

### Technology Stack

- **Cloudflare Workers**: Serverless edge computing platform
- **Supabase**: PostgreSQL database with real-time capabilities
- **TypeScript**: Type-safe development
- **OpenAI/Anthropic**: AI content analysis providers
- **Google OAuth**: User authentication

### Architecture Overview

The application follows a **layered architecture** pattern with clear separation of concerns:

```
src/
├── controllers/     # HTTP request handlers
├── services/        # Business logic layer
├── middleware/      # HTTP middleware
├── utils/          # Pure utility functions
├── types/          # Type definitions
├── routes.ts       # Main routing logic
└── index.ts        # Application entry point
```

### Key Components

#### Controllers
- **AuthController**: Handles authentication HTTP requests
- **AnalysisController**: Handles content analysis HTTP requests

#### Services
- **AuthService**: Authentication business logic (Google OAuth, JWT)
- **AnalysisService**: Content analysis orchestration
- **CacheService**: Multi-factor caching with intelligent invalidation
- **RateLimitService**: Daily limits and usage tracking
- **ValidationService**: Request validation and sanitization

#### Middleware
- **AuthMiddleware**: Authentication and authorization middleware

#### Utilities
- **Response Utilities**: Standardized HTTP response handling

### Design Principles

1. **Separation of Concerns**: Business logic separated from HTTP concerns
2. **Dependency Injection**: Services are injected into controllers
3. **Single Responsibility**: Each class has a single, well-defined purpose
4. **Type Safety**: Full TypeScript coverage with strict typing
5. **Error Handling**: Graceful degradation with user-friendly messages

## Setup

### Prerequisites

- Node.js 18+ 
- Wrangler CLI
- Supabase account
- OpenAI API key
- Anthropic API key
- Google OAuth credentials

### Installation

1. **Install dependencies**:
   ```bash
   npm install
   ```

2. **Configure environment variables**:
   Create a `.dev.vars` file for local development:
   ```env
   SUPABASE_URL=your-supabase-url
   SUPABASE_ANON_KEY=your-supabase-anon-key
   OPENAI_API_KEY=your-openai-api-key
   ANTHROPIC_API_KEY=your-anthropic-api-key
   JWT_SECRET=your-jwt-secret
   GOOGLE_CLIENT_ID=your-google-client-id
   ```

3. **Set up Supabase database**:
   Run the SQL scripts in `database/schema.sql` to create the required tables.

### Development

```bash
# Start development server
npm run dev

# Type checking
npm run type-check

# Run tests
npm test

# Build for production
npm run build

# Deploy to Cloudflare Workers
npm run deploy
```

## API Endpoints

### Authentication

#### POST /google/sign_in
Authenticate user with Google OAuth.

**Request Body**:
```json
{
  "idToken": "google-id-token"
}
```

**Response**:
```json
{
  "token": "jwt-token",
  "user": {
    "id": "user-id",
    "email": "user@example.com",
    "name": "User Name",
    "pictureUrl": "https://example.com/picture.jpg"
  },
  "isNewUser": false
}
```

#### POST /auth/logout
Logout user and invalidate token.

**Headers**: `Authorization: Bearer <token>`

**Response**:
```json
{
  "message": "Successfully logged out"
}
```

#### POST /auth/verify
Verify JWT token validity.

**Headers**: `Authorization: Bearer <token>`

**Response**:
```json
{
  "valid": true,
  "user": {
    "userId": "user-id",
    "email": "user@example.com",
    "name": "User Name"
  }
}
```

### Content Analysis

#### POST /analyze-quick
Quick analysis of content to determine if it's AI-generated.

**Headers**: `Authorization: Bearer <token>`

**Request Body**:
```json
{
  "url": "https://example.com/article",
  "text": "The first 500 words of content to analyze...",
  "mode": "quick",
  "lastModified": "2024-01-15T10:30:00Z"
}
```

**Response**:
```json
{
  "classification": "ai-generated",
  "confidenceLevel": "high",
  "confidenceScore": 0.85,
  "keyIndicators": ["repetitive patterns", "formal tone"],
  "reasoning": "The text exhibits characteristics typical of AI-generated content...",
  "metadata": {
    "wordCount": 450,
    "provider": "openai",
    "analysisTime": 1250
  },
  "cacheStatus": "miss"
}
```

#### POST /analyze-deep
Comprehensive analysis with detailed reasoning.

**Headers**: `Authorization: Bearer <token>`

**Request Body**: Same as quick analysis but with `"mode": "deep"`

**Response**: Same structure as quick analysis but with more detailed indicators and reasoning.

## Database Schema

### Users Table
Stores user information from Google OAuth.

### Token Blacklist Table
Tracks invalidated JWT tokens for security.

### Cache Entries Table
Stores analysis results with composite unique index on `(url_hash, content_hash, mode)`.

### Usage Analytics Table
Tracks daily usage per user for rate limiting.

## Caching Strategy

The system uses a sophisticated multi-factor cache key strategy:

- **URL Hash**: Normalized URL for consistent identification
- **Content Hash**: SHA-256 of analyzed text for change detection
- **Mode**: Separate caches for quick and deep analysis
- **TTL**: 24-hour cache expiration for freshness

### Cache Invalidation

- **Content Changes**: Automatic invalidation when content hash changes
- **Time-based**: 24-hour expiration for freshness
- **Manual**: Admin-triggered cache clearing

## Rate Limiting

- **Daily Limit**: 50 analyses per day per authenticated user
- **User Tracking**: Based on authenticated user IDs
- **Abuse Prevention**: Pattern detection and progressive limits

## Error Handling

The system provides graceful degradation:

- **AI Provider Outages**: Automatic fallback between OpenAI and Claude
- **Network Issues**: Retry logic with exponential backoff
- **Database Failures**: Continue operation with degraded caching
- **Authentication Errors**: Clear error messages and guidance
- **User-Friendly Messages**: Clear error descriptions and retry guidance

## Testing

The application includes comprehensive test coverage:

```bash
# Run all tests
npm test

# Run tests with coverage
npm run test:coverage

# Run specific test suites
npm test -- --testNamePattern="AuthService"
```

### Test Structure

- **Service Tests**: Unit tests for business logic
- **Controller Tests**: Integration tests for HTTP handlers
- **Middleware Tests**: Authentication and validation tests

## Deployment

### Cloudflare Workers

1. **Configure Wrangler**:
   ```bash
   wrangler login
   ```

2. **Set environment variables**:
   ```bash
   wrangler secret put SUPABASE_URL
   wrangler secret put SUPABASE_ANON_KEY
   wrangler secret put OPENAI_API_KEY
   wrangler secret put ANTHROPIC_API_KEY
   wrangler secret put JWT_SECRET
   wrangler secret put GOOGLE_CLIENT_ID
   ```

3. **Deploy**:
   ```bash
   npm run deploy
   ```

### Supabase Setup

1. Create a new Supabase project
2. Run the database schema scripts
3. Configure Row Level Security policies
4. Set up connection pooling for production

## Monitoring

The system includes comprehensive monitoring:

- **Request Volume**: Track usage patterns and growth
- **Cache Effectiveness**: Monitor hit rates and storage utilization
- **Error Tracking**: Identify and resolve issues quickly
- **Cost Monitoring**: Track API usage and optimize spending
- **Authentication Metrics**: Monitor login patterns and security

## Security

- **HTTPS Everywhere**: All communications encrypted
- **JWT Tokens**: Secure authentication with expiration
- **Token Blacklisting**: Secure logout with token invalidation
- **Row Level Security**: Database-level access controls
- **Environment Variables**: Sensitive configuration isolated
- **No Content Storage**: Only cryptographic hashes stored

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes with proper TypeScript types
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

### Development Guidelines

- Follow the layered architecture pattern
- Add comprehensive tests for new services
- Use TypeScript strict mode
- Document new endpoints and services
- Follow existing code style and patterns

## License

MIT License - see LICENSE file for details.
